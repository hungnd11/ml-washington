{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using deep features to train an image classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate as tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = tc.SFrame('data/image_train_data/')\n",
    "image_test = tc.SFrame('data/image_test_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore this image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "Height: 32px\n",
       "Width: 32px\n",
       "Channels: 3"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "image/png": {
       "Channels: ": "3",
       "Height": "32",
       "Width": "32"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_train['image'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an image classifier on raw image pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 1904</pre>"
      ],
      "text/plain": [
       "Number of examples          : 1904"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 4</pre>"
      ],
      "text/plain": [
       "Number of classes           : 4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 1</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 3072</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 3072"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients      : 9219</pre>"
      ],
      "text/plain": [
       "Number of coefficients      : 9219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy | Validation Accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy | Validation Accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 0         | 5        | 0.072337  | 1.244606     | 0.375000          | 0.366337            |</pre>"
      ],
      "text/plain": [
       "| 0         | 5        | 0.072337  | 1.244606     | 0.375000          | 0.366337            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 8        | 0.361687  | 1.416991     | 0.383403          | 0.346535            |</pre>"
      ],
      "text/plain": [
       "| 1         | 8        | 0.361687  | 1.416991     | 0.383403          | 0.346535            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 10       | 0.361687  | 1.546759     | 0.405462          | 0.386139            |</pre>"
      ],
      "text/plain": [
       "| 2         | 10       | 0.361687  | 1.546759     | 0.405462          | 0.386139            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 12       | 0.361687  | 1.674334     | 0.430672          | 0.425743            |</pre>"
      ],
      "text/plain": [
       "| 3         | 12       | 0.361687  | 1.674334     | 0.430672          | 0.425743            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 13       | 0.452109  | 1.765315     | 0.443277          | 0.415842            |</pre>"
      ],
      "text/plain": [
       "| 4         | 13       | 0.452109  | 1.765315     | 0.443277          | 0.415842            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 9         | 18       | 1.000000  | 2.206811     | 0.519958          | 0.366337            |</pre>"
      ],
      "text/plain": [
       "| 9         | 18       | 1.000000  | 2.206811     | 0.519958          | 0.366337            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_pixel_model = tc.logistic_classifier.create(image_train,\n",
    "                                                target = 'label',\n",
    "                                                features = ['image_array'], \n",
    "                                                seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions using simple raw pixel model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "Height: 32px\n",
       "Width: 32px\n",
       "Channels: 3"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "image/png": {
       "Channels: ": "3",
       "Height": "32",
       "Width": "32"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_test[0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_test[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: str\n",
       "Rows: 3\n",
       "['bird', 'cat', 'bird']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_pixel_model.predict(image_test[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the raw pixel model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.4785,\n",
       " 'auc': 0.7118264166666666,\n",
       " 'confusion_matrix': Columns:\n",
       " \ttarget_label\tstr\n",
       " \tpredicted_label\tstr\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 16\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |     bird     |       dog       |  137  |\n",
       " |     dog      |       cat       |  246  |\n",
       " |     cat      |       cat       |  347  |\n",
       " |     dog      |    automobile   |   77  |\n",
       " |     dog      |       dog       |  381  |\n",
       " |     cat      |       dog       |  245  |\n",
       " |     bird     |    automobile   |   87  |\n",
       " |  automobile  |    automobile   |  594  |\n",
       " |     bird     |       cat       |  184  |\n",
       " |     cat      |    automobile   |  121  |\n",
       " +--------------+-----------------+-------+\n",
       " [16 rows x 3 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.,\n",
       " 'f1_score': 0.47746452330448125,\n",
       " 'log_loss': 1.2469852106364125,\n",
       " 'precision': 0.48408359676195145,\n",
       " 'recall': 0.47850000000000004,\n",
       " 'roc_curve': Columns:\n",
       " \tthreshold\tfloat\n",
       " \tfpr\tfloat\n",
       " \ttpr\tfloat\n",
       " \tp\tint\n",
       " \tn\tint\n",
       " \tclass\tint\n",
       " \n",
       " Rows: 400004\n",
       " \n",
       " Data:\n",
       " +-----------+-----+-----+------+------+-------+\n",
       " | threshold | fpr | tpr |  p   |  n   | class |\n",
       " +-----------+-----+-----+------+------+-------+\n",
       " |    0.0    | 1.0 | 1.0 | 1000 | 3000 |   0   |\n",
       " |   1e-05   | 1.0 | 1.0 | 1000 | 3000 |   0   |\n",
       " |   2e-05   | 1.0 | 1.0 | 1000 | 3000 |   0   |\n",
       " |   3e-05   | 1.0 | 1.0 | 1000 | 3000 |   0   |\n",
       " |   4e-05   | 1.0 | 1.0 | 1000 | 3000 |   0   |\n",
       " |   5e-05   | 1.0 | 1.0 | 1000 | 3000 |   0   |\n",
       " |   6e-05   | 1.0 | 1.0 | 1000 | 3000 |   0   |\n",
       " |   7e-05   | 1.0 | 1.0 | 1000 | 3000 |   0   |\n",
       " |   8e-05   | 1.0 | 1.0 | 1000 | 3000 |   0   |\n",
       " |   9e-05   | 1.0 | 1.0 | 1000 | 3000 |   0   |\n",
       " +-----------+-----+-----+------+------+-------+\n",
       " [400004 rows x 6 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_pixel_model.evaluate(image_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train image classifier using deep features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2005"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">id</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">label</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">deep_features</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image_array</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">24</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">bird</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.24287176132202148,<br>1.0954537391662598, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[73.0, 77.0, 58.0, 71.0,<br>68.0, 50.0, 77.0, 69.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">33</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">cat</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.5250879526138306, 0.0,<br>0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[7.0, 5.0, 8.0, 7.0, 5.0,<br>8.0, 5.0, 4.0, 6.0, 7.0, ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[2 rows x 5 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tid\tint\n",
       "\timage\tImage\n",
       "\tlabel\tstr\n",
       "\tdeep_features\tarray\n",
       "\timage_array\tarray\n",
       "\n",
       "Rows: 2\n",
       "\n",
       "Data:\n",
       "+----+----------------------+-------+-------------------------------+\n",
       "| id |        image         | label |         deep_features         |\n",
       "+----+----------------------+-------+-------------------------------+\n",
       "| 24 | Height: 32 Width: 32 |  bird | [0.24287176132202148, 1.09... |\n",
       "| 33 | Height: 32 Width: 32 |  cat  | [0.5250879526138306, 0.0, ... |\n",
       "+----+----------------------+-------+-------------------------------+\n",
       "+-------------------------------+\n",
       "|          image_array          |\n",
       "+-------------------------------+\n",
       "| [73.0, 77.0, 58.0, 71.0, 6... |\n",
       "| [7.0, 5.0, 8.0, 7.0, 5.0, ... |\n",
       "+-------------------------------+\n",
       "[2 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given the deep features, train a logistic classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 1904</pre>"
      ],
      "text/plain": [
       "Number of examples          : 1904"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 4</pre>"
      ],
      "text/plain": [
       "Number of classes           : 4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 1</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 4096</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 4096"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients      : 12291</pre>"
      ],
      "text/plain": [
       "Number of coefficients      : 12291"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy | Validation Accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy | Validation Accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 0         | 3        | 0.500000  | 0.268926     | 0.745273          | 0.663366            |</pre>"
      ],
      "text/plain": [
       "| 0         | 3        | 0.500000  | 0.268926     | 0.745273          | 0.663366            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 6        | 0.250000  | 0.616040     | 0.775210          | 0.762376            |</pre>"
      ],
      "text/plain": [
       "| 1         | 6        | 0.250000  | 0.616040     | 0.775210          | 0.762376            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 8        | 0.304300  | 0.887187     | 0.776786          | 0.762376            |</pre>"
      ],
      "text/plain": [
       "| 2         | 8        | 0.304300  | 0.887187     | 0.776786          | 0.762376            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 12       | 0.912900  | 1.316751     | 0.765231          | 0.722772            |</pre>"
      ],
      "text/plain": [
       "| 3         | 12       | 0.912900  | 1.316751     | 0.765231          | 0.722772            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 14       | 1.000000  | 1.588303     | 0.803571          | 0.742574            |</pre>"
      ],
      "text/plain": [
       "| 4         | 14       | 1.000000  | 1.588303     | 0.803571          | 0.742574            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 9         | 22       | 0.976563  | 2.772848     | 0.933298          | 0.772277            |</pre>"
      ],
      "text/plain": [
       "| 9         | 22       | 0.976563  | 2.772848     | 0.933298          | 0.772277            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deep_features_model = tc.logistic_classifier.create(image_train,\n",
    "                                                    target='label',\n",
    "                                                    features = ['deep_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the deep features classifier on the first few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "Height: 32px\n",
       "Width: 32px\n",
       "Channels: 3"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "image/png": {
       "Channels: ": "3",
       "Height": "32",
       "Width": "32"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_test['image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_test['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: str\n",
       "Rows: 3\n",
       "['cat', 'automobile', 'cat']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_features_model.predict(image_test[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitatively evaluate deep features classifier on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.794,\n",
       " 'auc': 0.942758166666668,\n",
       " 'confusion_matrix': Columns:\n",
       " \ttarget_label\tstr\n",
       " \tpredicted_label\tstr\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 16\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |     bird     |       dog       |   41  |\n",
       " |     dog      |       cat       |  203  |\n",
       " |     dog      |    automobile   |   11  |\n",
       " |     cat      |       bird      |   92  |\n",
       " |  automobile  |       dog       |   7   |\n",
       " |     dog      |       bird      |   64  |\n",
       " |     cat      |    automobile   |   26  |\n",
       " |     cat      |       cat       |  660  |\n",
       " |     bird     |       cat       |  112  |\n",
       " |     cat      |       dog       |  222  |\n",
       " +--------------+-----------------+-------+\n",
       " [16 rows x 3 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.,\n",
       " 'f1_score': 0.7937331248459303,\n",
       " 'log_loss': 0.5840546223530734,\n",
       " 'precision': 0.7934903853849173,\n",
       " 'recall': 0.7939999999999999,\n",
       " 'roc_curve': Columns:\n",
       " \tthreshold\tfloat\n",
       " \tfpr\tfloat\n",
       " \ttpr\tfloat\n",
       " \tp\tint\n",
       " \tn\tint\n",
       " \tclass\tint\n",
       " \n",
       " Rows: 400004\n",
       " \n",
       " Data:\n",
       " +-----------+--------------------+-----+------+------+-------+\n",
       " | threshold |        fpr         | tpr |  p   |  n   | class |\n",
       " +-----------+--------------------+-----+------+------+-------+\n",
       " |    0.0    |        1.0         | 1.0 | 1000 | 3000 |   0   |\n",
       " |   1e-05   | 0.8976666666666666 | 1.0 | 1000 | 3000 |   0   |\n",
       " |   2e-05   | 0.8693333333333333 | 1.0 | 1000 | 3000 |   0   |\n",
       " |   3e-05   | 0.8453333333333334 | 1.0 | 1000 | 3000 |   0   |\n",
       " |   4e-05   | 0.8286666666666667 | 1.0 | 1000 | 3000 |   0   |\n",
       " |   5e-05   |        0.81        | 1.0 | 1000 | 3000 |   0   |\n",
       " |   6e-05   | 0.7926666666666666 | 1.0 | 1000 | 3000 |   0   |\n",
       " |   7e-05   |        0.78        | 1.0 | 1000 | 3000 |   0   |\n",
       " |   8e-05   | 0.7656666666666667 | 1.0 | 1000 | 3000 |   0   |\n",
       " |   9e-05   | 0.7546666666666667 | 1.0 | 1000 | 3000 |   0   |\n",
       " +-----------+--------------------+-----+------+------+-------+\n",
       " [400004 rows x 6 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_features_model.evaluate(image_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
